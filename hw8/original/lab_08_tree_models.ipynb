{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d62bf3-9f5f-499b-8a43-3f1f8199bc56",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Decision tree based models\n",
    "\n",
    "This week we will use the <a href='https://archive.ics.uci.edu/ml/machine-learning-databases/00603/in-vehicle-coupon-recommendation.csv'>vehincle coupon recommendation dataset</a>. Our goal is to classify people based on their driving habits whether they would accept a vehicle coupon or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bd5a1b-121d-480b-93fc-d27db45dcafb",
   "metadata": {},
   "source": [
    "## I. Prepare dataset\n",
    "\n",
    "1.   Load the `in-vehicle-coupon-recommendation.csv` dataset\n",
    "2.   Search for missing values and if needed, handle them!\n",
    "3.   Encode the non numeric variables into numeric ones! For the binary\n",
    "     features simply encode them as ($0$/$1$). Do not create two separate\n",
    "     columns for them! You'll have to use the description of the dataset\n",
    "     provided at its download location!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51630823-d8ad-4a1b-89f1-b319d378f210",
   "metadata": {},
   "source": [
    "## II. Train & visualize decision tree classifier\n",
    "\n",
    "1.   Train a **decision tree classifier** using the `sklearn` API\n",
    "     -   Use its default parameters\n",
    "     -   Use all the data\n",
    "2.   Visualize the decision tree, with the *Gini impurities* also showing on the\n",
    "     plot. The `plot_tree` function in `sklearn` will be really helpful. You\n",
    "     may or may not need to tune its arguments to get a reasonable result.\n",
    "3.   Manually check for the labels and for an arbitrary feature whether the\n",
    "     returned *Gini impurities* are correct\n",
    "4.   In a few sentences, discuss the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dcca44-4fe3-4a75-9996-3c1827add2a1",
   "metadata": {},
   "source": [
    "## III. Random forest feature importance\n",
    "\n",
    "1.   Train a random forest classifier on all the data using the sklearn API\n",
    "     -   Use default values again, but fix the `random_state` to $57$!\n",
    "2.   Plot the importance values of the $10$ most important features\n",
    "     -   Create a bar plot where the height of the bar is the feature importance\n",
    "     -   The `feature_importances_` attribute is helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba3c92-6c78-44cb-b6e6-d4ec3f04525c",
   "metadata": {},
   "source": [
    "## IV. Evaluation\n",
    "\n",
    "1.   Generate prediction probabilities with a **decision tree** and with a\n",
    "     **random forest model**\n",
    "     -   Use $5$-fold cross validation for both models\n",
    "     -   Use default parameters for both models\n",
    "2.   Compare the two models with ROC curves\n",
    "     -   Why does the shape of the decision tree's ROC curve looks different?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b4af16-f3f6-4c8f-b15e-5d4ea0e0d85d",
   "metadata": {},
   "source": [
    "## V. Tuning model\n",
    "\n",
    "1.   Using $80\\%$ - $20\\%$ train-test split generate predictions for a **random\n",
    "     forest model**\n",
    "     -   Set the `random_state` parameter for every run to $57$ for the\n",
    "         train-test split and for the Random Forest Classifier as well!\n",
    "2.   Plot the AUC as the function of the number of trees in the forest for both\n",
    "     the traing and the test data!\n",
    "3.   Do we experience overfitting if we use too many trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb65bf0-a768-463c-90ef-81588785ec11",
   "metadata": {},
   "source": [
    "### Hints:\n",
    "\n",
    "-   On total you can get $10$ points for fully completing all tasks.\n",
    "-   Decorate your notebook with, questions, explanation etc., make it\n",
    "    self-contained and understandable!\n",
    "-   Comment your code when necessary\n",
    "-   Write functions for repetitive tasks!\n",
    "-   Use the `pandas` package for data loading and handling\n",
    "-   Use `matplotlib` and `seaborn` for plotting or `bokeh` and `plotly` for\n",
    "    interactive investigation.\n",
    "-   Use the `scikit-learn` package for almost everything\n",
    "-   Use for loops only if it is really necessary!\n",
    "-   Code sharing is not allowed between student! Sharing code will\n",
    "    result in zero points.\n",
    "-   If you use code found on web, it is OK, **but, make its source clear**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
